{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import with_statement\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy\n",
    "import deepmodels\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import os.path\n",
    "import subprocess\n",
    "import imageutils\n",
    "import utils\n",
    "import deepmodels_torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/lfw/lfw_binary_attributes.json') as f: lfw=json.load(f)\n",
    "with open('datasets/lfw/filelist.txt','r') as f: lfw_filelist=['images/'+x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lfw_filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'torch'\n",
    "device_id = 0\n",
    "K = 100\n",
    "scaling = 'beta'\n",
    "itera = 500\n",
    "postprocess=set('color'.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_manifolds(a,s=[],t=[],N=10,X=None,visualize=False):\n",
    "    '''\n",
    "    a is the target attribute, s are exclusive attributes for the source,\n",
    "    t are exclusive attributes for the target.\n",
    "    '''\n",
    "    S={k:set(v) for k,v in lfw['attribute_members'].items()}\n",
    "    T=lfw['attribute_gender_members']\n",
    "    G=set(T[lfw['attribute_gender'][a]])\n",
    "    if X is None:\n",
    "        # test has correct gender, all of the source attributes and none of the target attributes\n",
    "        X=[i for i in range(len(lfw_filelist)) if i in G and i not in S[a] and not any(i in S[b] for b in t) and all(i in S[b] for b in s)]\n",
    "        random.seed(123)\n",
    "        random.shuffle(X)\n",
    "    else:\n",
    "        X=[lfw_filelist.index(x) for x in X]\n",
    "\n",
    "    def distfn(y,z):\n",
    "        fy=[True if y in S[b] else False for b in sorted(S.keys())]\n",
    "        fz=[True if z in S[b] else False for b in sorted(S.keys())]\n",
    "        return sum(0 if yy==zz else 1 for yy,zz in zip(fy,fz))\n",
    "    # source has correct gender, all of the source attributes and none of the target attributes\n",
    "    # ranked by attribute distance to test image\n",
    "    P=[i for i in range(len(lfw_filelist)) if i in G and i not in S[a] and not any(i in S[b] for b in t) and all(i in S[b] for b in s)]\n",
    "    P=[sorted([j for j in P if j!=X[i]],key=lambda k: distfn(X[i],k)) for i in range(N)]\n",
    "    # target has correct gender, none of the source attributes and all of the target attributes\n",
    "    Q=[i for i in range(len(lfw_filelist)) if i in G and i in S[a] and not any(i in S[b] for b in s) and all(i in S[b] for b in t)]\n",
    "    Q=[sorted([j for j in Q if j!=X[i] and j not in P[i]],key=lambda k: distfn(X[i],k)) for i in range(N)]\n",
    "\n",
    "    return [lfw_filelist[x] for x in X],[[lfw_filelist[x] for x in y] for y in P],[[lfw_filelist[x] for x in y] for y in Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_resolution=200\n",
    "if backend=='torch':\n",
    "    model=deepmodels_torch.vgg19g_torch(device_id=device_id)\n",
    "elif backend=='caffe+scipy':\n",
    "    model=deepmodels.vgg19g(device_id=device_id)\n",
    "else:\n",
    "    raise ValueError('Unknown backend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('images/lfw_aegan'):\n",
    "    url='https://www.dropbox.com/s/isz4ske2kheuwgr/lfw_aegan.tar.gz?dl=1'\n",
    "    subprocess.check_call(['wget',url,'-O','lfw_aegan.tar.gz'])\n",
    "    subprocess.check_call(['tar','xzf','lfw_aegan.tar.gz'])\n",
    "    subprocess.check_call(['rm','lfw_aegan.tar.gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=numpy.load('tests/dmt2-lfw-multiple-attribute-test.npz')\n",
    "pairs=list(data['pairs'][[0,1,2,4,5,6]]) # skip flushed face, not interesting\n",
    "X=data['X']\n",
    "X=X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=100\n",
    "delta = '0.4'\n",
    "delta_params=[float(x.strip()) for x in delta.split(',')]\n",
    "# t0=time.time()\n",
    "result=[]\n",
    "original=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    result.append([])\n",
    "    xX=X[i].decode('utf-8').replace('lfw','lfw_aegan')\n",
    "    o=imageutils.read(xX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dims=o.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if min(image_dims)<minimum_resolution:\n",
    "    s=float(minimum_resolution)/min(image_dims)\n",
    "    image_dims=(int(round(image_dims[0]*s)),int(round(image_dims[1]*s)))\n",
    "    o=imageutils.resize(o,image_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vk352/FaceDetection/deepfeatinterp/deepmodels_torch.py:137: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  input_var = Variable(input, volatile=True).cuda()\n"
     ]
    }
   ],
   "source": [
    "XF=model.mean_F([o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x.decode('UTF-8') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,(a,b) in enumerate([pairs[0]]):\n",
    "    _,P,Q=make_manifolds(b.decode('UTF-8'),[a.decode('UTF-8')],[],X=X[0:1],N=1)\n",
    "P=P[0]\n",
    "Q=Q[0]\n",
    "xP=[x.replace('lfw','lfw_aegan') for x in P]\n",
    "xQ=[x.replace('lfw','lfw_aegan') for x in Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF=model.mean_F(utils.image_feed(xP[:K],image_dims))\n",
    "QF=model.mean_F(utils.image_feed(xQ[:K],image_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scaling=='beta':\n",
    "    WF=(QF-PF)/((QF-PF)**2).mean()\n",
    "elif scaling=='none':\n",
    "    WF=(QF-PF)\n",
    "max_iter=itera\n",
    "init=o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/lfw_aegan/Melchor_Cob_Castro/Melchor_Cob_Castro_0001.jpg b'Senior' 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vk352/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33898085355758667 minutes to reconstruct\n"
     ]
    }
   ],
   "source": [
    "for delta in delta_params:\n",
    "    print(xX,b,delta)\n",
    "    t2=time.time()\n",
    "    Y=model.F_inverse(XF+WF*delta,max_iter=max_iter,initial_image=init)\n",
    "    t3=time.time()\n",
    "    print('{} minutes to reconstruct'.format((t3-t2)/60.0))\n",
    "    result[-1].append(Y)\n",
    "    max_iter=itera//2\n",
    "    init=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=numpy.asarray(result)\n",
    "original=numpy.asarray(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing color match (1, 1, 200, 200, 3) (1, 1, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "if 'color' in postprocess:\n",
    "    result=utils.color_match(numpy.expand_dims(original,1),result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=imageutils.montage(numpy.concatenate([numpy.expand_dims(original,1),result],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageutils.write('results/demo1vk2.png',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
